## Как запустить on Mac M1?
- если никак не удается установить spacy
- используйте следующий образ в проекте
```bash
docker compose up -d
```

```yml
services:
  spacy_app:
    image: continuumio/miniconda3
    container_name: spacy_container
    working_dir: /app
    volumes:
      - .:/app
    ports:
      - "8888:8888"
    command: >
      sh -c "conda update -n base -c defaults conda -y &&
             conda create -n spacy_env python=3.10.12 -y &&
             conda install -n spacy_env -c conda-forge spacy jupyter notebook -y &&
             mkdir -p /root/.jupyter &&
             echo 'c.NotebookApp.token = \"\"' > /root/.jupyter/jupyter_notebook_config.py &&
             echo 'c.NotebookApp.password = \"\"' >> /root/.jupyter/jupyter_notebook_config.py &&
             conda run -n spacy_env python -m spacy download en_core_web_sm &&
             conda run -n spacy_env jupyter notebook --ip=0.0.0.0 --port=8888 --allow-root --NotebookApp.token='' --NotebookApp.password=''"
```

#### 0. Методы тестирования
- Сравнение N версий - невозможно предсказать для уникальные программы единственные в своем роде
- Неявные implicit оракулы проверяют только общее генерализованное состояние
- Фаззинг - непредвиденные входные данные. Как один из видов стрессового тестирования (не нагрузки)
- Triple AAA (Arrange, Act, Assert) - самое понятное, ожидаемый конечныцй результат
- Тестирование инвариантами - давайте по входным данным смотреть как изменится выходной результат

**Тестовый оракул** — это механизм или источник, который определяет, является ли результат выполнения теста правильным.

Типы тестовых оракулов:

- Полный оракул – точно знает, каким должен быть правильный результат (например, эталонная модель)
- Частичный оракул – проверяет отдельные свойства результата (например, сумма вероятностей = 1)
- Эвристический оракул – использует приближённые методы (например, сравнение с предыдущими версиями)

### 1. Опишите суть проблемы тестового оракула.
Тестовый оракул определяет правильность вывода программы. 
- Сложность определения oracle (критериев проверки)
- Необходимость подбирать данные (в случае машинного обучения - принципиальное ограничение)
- Длительное время выполнения тестов
- Культурные сложности – незнание методов, непонимание важности тестирования

Проблема в том, что для многих сложных или неизвестных систем оракул либо отсутствует, либо его создание бывает слишком дорого или трудоемко (ручной труд). Вот основные проблемы:
- Нет явного эталона истинности
- Тестовый оракул не может охватывать все сценарии, а ручное тестирование каждого из аспектов трудоемко
- Не существует универсального оракула, 
- Тестовый оракул - частичная функция из множества последовательности тестовых действий во множество{true, false}
- Не для всех задач тестовый оракул может быть вычислен за разумное время
- Существуют вероятностные оракулы, ответом которых является значение из интервала [0,1].

Проблема тестового оракула остаётся актуальной в тестировании, 
тк во многих случаях невозможно **автоматически** и **точно** определить корректность выходных данных. 
Решение этой проблемы требует комбинированного подхода, включающего:
- автоматизацию
- экспертную проверку

----

### 2. Приведите примеры задач, для которых обычное тестирование с оракулом не подходит.
там где заранее нельзя определить верный результат

- **ML** где не всегда можно предсказать точный правильный ответ  
- **Компиляторы** - здесь сложно определить, каким должен быть выходной код. 
- **Эмуляция физических процессов реального мира** - результаты скорее приближенными, а не точные

Применяется:
- Вычисление количества сложных комбинаторных объектов
- Определение мутаций для больших геномов
- Тестирование модели ML на неразмеченной выборке без возможности доразметки
- Проверка веб-сервисов социальных сетей
- Проверка киберфизических систем (лифты)

Для подобных задач вычисление правильного ответа требует слишком много ресурсов либо в принципе невозможно.


Еще примеры. Есть несколько классов задач, для которых обычное тестирование с тестовым оракулом не подходит, 
поскольку невозможно заранее определить, каким должен быть правильный результат. 
Рассмотрим несколько примеров:

#### 1. Машинное обучение и нейросетевые модели (Классификация изображений, распознавание речи, генерация текста)
- !Нет строгого эталонного ответа.
К примеру алгоритм обработки естественного языка может выдавать несколько разных, но корректных вариантов ответа.

**Как тестируют:**
- Сравнение с эталонными примерами (но не все возможные ответы можно предусмотреть)
- Использование метрик качества (точность, полнота, F1-score)
- A/B-тестирование на реальных пользователях

#### 2. Системы моделирования и прогнозирования (Прогноз погоды, симуляция физических процессов, экономические прогнозы)

- **!Даже при реальных данных,** модель может выдавать разные результаты в зависимости от параметров. Идеального предсказания не существует.

**Как тестируют:**
- Сравнение с историческими данными (но прогноз всегда приблизителен)
- Проверка на соответствие физическим законам или статистическим моделям
- Оценка точности прогнозов на больших временных интервалах

#### 3. Автономные системы и робототехника (Автономные автомобили, дроны, роботы-помощники)

- **!Среда взаимодействия изменчива,** и заранее неизвестно, какой путь, скорость или манёвр является оптимальным в каждой ситуации.

**Как тестируют:**
- Моделирование сценариев (но охватить все возможные сценарии невозможно).
- Оценка эффективности работы в реальных условиях (например, количество предотвращённых аварий)

#### 4. Компьютерные игры и генеративные алгоритмы (Генерация уровней в игре, NPC-искусственный интеллект)

- **!Невозможно заранее определить,** какие решения NPC должны принимать в каждой ситуации

**Как тестируют:**
- Тестирование через игроков (юзабилити-тестирование).

#### 5. Биологическое и медицинское моделирование (Разработка новых лекарств, моделирование клеточных процессов)
- !Почему нет оракула: Даже лучшие модели организма работают с упрощенными моделями, а эффект лекарства может **зависеть от множества факторов**.

**Как тестируют:**
- Сравнение с реальными экспериментами
- Использование статистики больших выборок.

#### 6. Творческие алгоритмы (Генерация музыки, живописи, текстов, AI-художники)
- !Почему нет оракула: **Нет «правильного» ответа,** так как восприятие искусства субъективно.
Как тестируют:
- Оценка экспертами или пользователями.
- Анализ статистики (вовлечённость, время взаимодействия с контентом).

**_Во всех этих случаях невозможно создать точный тестовый оракул, потому что:_**

- _Результаты неоднозначны или стохастичны._
- _Оценка качества субъективна._
- _Тестируемая система адаптируется или изменяется во времени._

----

### 3. Перечислите методы, которые применяются для решения этой проблемы.
Проблема тестового оракула не имеет универсального решения, но можно использовать комбинацию методов:
- **Эвристики** – если точный результат неизвестен, можно проверять примерное значение.
  - **Property-Based Testing** – например, сумма вероятностей в модели должна быть равна 1
  - **Анализ инвариантов** – тестируется неизменное свойство системы (например, баланс счёта в банке не может быть отрицательным)
  - **Статистические методы** – например, в прогнозе погоды температура не может резко меняться на 50°C за 1 минуту 


- **Сравнение с альтернативами** – если нет эталона, можно сравнивать версии.
- **Статистика** – если нет конкретного ответа, можно анализировать закономерности.
- **Люди** – если алгоритмы не могут оценить результат, можно привлекать экспертов.
- **Искусственный интеллект** – если тестирование сложное, можно использовать AI для автоматического анализа.

В реальной практике выбирают гибридный подход, комбинируя несколько методов. 🎯

----

### 4. Дайте определение тестового инварианта (metamorphic relation).

_Если программа изменяет входные данные определённым образом, то и выходные данные должны изменяться предсказуемым образом._

- нет эталона
- проверяется закономерность
- чаще всего проверка определенных свойств тк нет явного результата

Тестирование инвариантами — это один из методов обхода проблемы отсутствия тестового оракула.


----


NER - named entity recognition

## 1. Тестовый оракул

```python
import spacy
import unittest

# Загружаем модель NLP (используем английскую модель из либы spacy)
# для NER задачи - named entity recognition
nlp = spacy.load("en_core_web_sm")

def extract_entities(text):
    doc = nlp(text)
    return [(ent.text, ent.label_) for ent in doc.ents]

class Task1(unittest.TestCase):
    def test_with_oracle1(self):
        """Test Case #1 
        Распознавание организаций (ORG)
        """
        text = "Google and Microsoft are competing in the AI market"
        
        expected_entities = [("Google", "ORG"), ("Microsoft", "ORG")]
        extracted_entities = extract_entities(text)

        for entity in expected_entities:
            self.assertIn(entity, extracted_entities)
            break

    def test_with_oracle2(self):
        """Test Case #2
        Распознавание географических мест (LOC) - locations
        """
        text = "I traveled from Paris to London last summer"
        
        expected_entities = [("Paris", "GPE"), ("London", "GPE")]
        extracted_entities = extract_entities(text)
        
        for entity in expected_entities:
            self.assertIn(entity, extracted_entities)

if __name__ == "__main__":
    loader = unittest.TestLoader()
    tests = loader.loadTestsFromTestCase(Task1)
    print(f"Найдено {tests.countTestCases()} тестов")
    unittest.main(argv=['first-arg-is-ignored'], exit=False)

```

## 2. Тестирование с инвариантами
```python
import random

class Task2(unittest.TestCase):

    # Порядок слов не влияет на набор сущностей	
    # !!! В отличие от трансформеров, таких как BERT, spaCy использует CNN и LSTM, которые менее устойчивы к изменению порядка слов.
    def test_metamorphic1(self):
        text = "Elon Musk is the CEO of Tesla"
        expected_entities = extract_entities(text)
    
        words = text.split()
        random.shuffle(words)  # Перемешиваем слова
        shuffled_text = " ".join(words)
    
        shuffled_entities = extract_entities(shuffled_text)
        self.assertEqual(set(expected_entities), set(shuffled_entities))


    # Добавление мусора и неинформативного контекста
    def test_metamorphic2(self):
        text = "Amazon is a large e-commerce company"
        expected_entities = extract_entities(text)
    
        noisy_text = "By the way, " + text + " as many people already know."
        noisy_entities = extract_entities(noisy_text)
    
        for entity in expected_entities:
            self.assertIn(entity, noisy_entities)

    
    #  Модель устойчива к замене синонимов
    def test_metamorphic3(self):
        text = "Google is a powerful technology company"
        synonym_text = "Google is a strong tech enterprise"
    
        original_entities = extract_entities(text)
        synonym_entities = extract_entities(synonym_text)
    
        # Проверяем, что сущности и их метки совпадают
        self.assertEqual(original_entities, synonym_entities)

if __name__ == "__main__":
    loader = unittest.TestLoader()
    tests = loader.loadTestsFromTestCase(Task2)
    print(f"Найдено {tests.countTestCases()} тестов")
    unittest.main(argv=['first-arg-is-ignored'], exit=False)
```

# Математическое доказательство корректности инвариантов NER  

## Инвариант 1 (MR1 - Перестановка слов без изменения смысла)  

Если порядок слов в предложении меняется (сохраняя смысл), то множество именованных сущностей (NER) и их метки остаются неизменными  

### Док-во:

Пусть **S** — исходное предложение, а **P(S)** — перестановка слов в **S**.  
Пусть **NER(S) = { (e₁, l₁), ..., (eₙ, lₙ) }** — множество найденных сущностей.  
Тогда:  

$$
NER(S) = NER(P(S))
$$  

Важно! При условии, что ни одна сущность не пересекается с изменёнными словестными константами
 
- в модели NER каждое слово обрабатывается независимо с учётом контекста (но не жёсткого порядка)  
- современные NER-модели (например, трансформеры) используют **self-attention**, и не зависят от точного порядка слов  
- если слово не изменилось, а контекст его сохранён, оно обязано иметь ту же метку  
- исключение — перестановка неразрывных сущностей (`"United States" → "States United"`) - это не нарушает инвариант, а лишь показывает ограниченность текущих моделей.  

## Инвариант 2 (MR2 - Добавление неинформативного контекста)

Если в текст добавляются слова, не меняющие смысл, то основное множество именованных сущностей остаётся неизменным 

### Док-во:  
Пусть **S' = S + Noise**, где **Noise** — случайные слова, не имеющие отношение к сущности  
Тогда:  

$$
NER(S) \subseteq NER(S')
$$  

тк все сущности из **S** сохраняются, в **S'** могут появиться новые, а старые не должны исчезнуть  

- современные модели должны быть хорошо обучены на текстах с разным уровнем "шума"
- если модель удаляет сущности из-за шума - значит что она слишком чувствительна к контексту - а это проблема.  
- новые слова не меняют контекст, а значит идентификация сущностей остается прежней
- условие выполняется, если добавленный шум не нарушает контекст распознаваемых имен  

---

## Инвариант 3 (MR3 - Замена синонимов без изменения структуры)
 
Если в предложении слова заменяются на синонимы без изменения структуры предложения - то множество именованных сущностей остаётся неизменным  

### Док-во:  
Пусть **S'** -> из **S** c заменой всех синонимов:  

$$
S' = SynonymReplace(S)
$$  

Тогда:  

$$
NER(S) = NER(S')
$$  


- векторные представления слов (**word embeddings**) позволяют обрабатывать семантически эквивалентные слова одинаково 
- cинонимы (например, `"firm" → "company"`, `"NYC" → "New York"`) имеют почти одинаковые векторные представления  
- замена одного слова на синоним не должна менять метку сущности, если её границы остаются неизменными  
- условие выполняется, если модель корректно интерпретирует семантические замены



### Недостатки
у каждого метода есть свои недостатки

- MR1 проявляет чувствительность к порядку слов
    - Учитывает контекст
    - сущности, такие как "United States" 
- MR2 — чувствителен добавлению шума:
    - Проверяет, устойчивость к "шуму" в тексте.
    - Полезен где много вводных слов и стилистических конструкций
    - NER-модели игноририрует сущности, если общий контекст изменен
    - Если "шум" добавлен неаккуратно, испортится предсказание
- MR3 — к семантическим подстановкам
    - полезен для языков где много синонимов
    - понимаем, насколько хорошо модель понимает семантику слов
    - понимаем близость векторов смежных слов
    - Некоторые синонимы могут менять регистр, грамматические связи или значение в контексте
    - для редких случаев ("фирма" → "организация") модель не всегда корректно идентифицировует сущности 








